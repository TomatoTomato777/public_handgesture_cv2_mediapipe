'''
this code has become a module. purpose of converting the code to be module format is to get those position
values of the landmarks easily

function:
this code will use cv2 to open camera,
then convert img to RGB
then use mediapipe to detect hands
after detect will label dots and line in hands
include fps
put circle on point 4


find position function of the finger
'''

import cv2
import mediapipe as mp
import time

'''
.Hands() requirements are:
static_image_mode = False,
max_num_hands = 2,
min_detection_confidence = 0.5,
min_tracking_confidence = 0.5

we create a handDetector() class to call the require parameter
so inside __init__() bracket, we declare the required parameter

__init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5) is same as:
static_image_mode = False,
max_num_hands = 2,
min_detection_confidence = 0.5,
min_tracking_confidence = 0.5

so purpose of class handDetector() is to declare all the requirements
'''

class handDetector():
    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):

        # static_image_mode = False,
        # max_num_hands = 2,
        # min_detection_confidence = 0.5,
        # min_tracking_confidence = 0.5

        self.mode = mode
        self.maxHands = maxHands
        self.detectionCon = detectionCon
        self.trackCon = trackCon

        self.mpHands = mp.solutions.hands       # hand landmark detection model
        self.hands = self.mpHands.Hands(static_image_mode=self.mode, max_num_hands=self.maxHands, min_detection_confidence=self.detectionCon,min_tracking_confidence=self.trackCon)
        self.mpDraw = mp.solutions.drawing_utils

    def findHands(self, img, draw=True):

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert img to RGB cuz mediapipe use RGB to detect
        self.results = self.hands.process(imgRGB)

        if self.results.multi_hand_landmarks:                                                     # if results.multi_hand_landmarks == True == if can detect hand # detect 1 hand or 2 hands...
            for handLms in self.results.multi_hand_landmarks:                                     # loop no.of detected hands
                if draw:                                                                     # if draw == True
                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)  # img == draw landmarks in the original img, not imgRGB
                                                                                             # handLms == to label dots
                                                                                             # mpHands.HAND_CONNECTIONS == to draw line
        return img

    def findPosition(self, img, handNo=0, draw=True):

        lmList = []
        if self.results.multi_hand_landmarks:
            myHand = self.results.multi_hand_landmarks[handNo]    # point to particular hand number # hand 1 or hand 2 or hand 3...

            for id, lm in enumerate(myHand.landmark):   # get 21 id points for each finger   # lm in enumerate(myHand.landmark) == getting landmark(lm) from myHand.landmark
                # print(id,lm)                           # id = 21 points ; lm = x, y, z coordinate
                h, w, c = img.shape                      # h,w,c == height,weight,channel. to find img's window size. h = img window pixel height. w = img window pixel width
                cx, cy = int(lm.x * w), int(lm.y * h)    # cx,cy = loop each 21 landmark points in pixel form
                #print(id, cx, cy)
                lmList.append([id,cx,cy])
                if draw:
                    cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)  # put circle on point 4
        return lmList


def main():
    pTime = 0
    cTime = 0
    cap = cv2.VideoCapture(0)
    detector = handDetector()       # no need to declare anything inside () cuz already declared __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5)

    while True:
        success, img = cap.read()
        img = detector.findHands(img)     # need to pass img to .findHands() for def findHands(self, img, draw=True): to process
                                          # img = detector.findHands(img) means return process detector.findHands(img) to img variable
        lmList = detector.findPosition(img)
        if len(lmList) != 0:
            print(lmList[4])

        cTime = time.time()
        fps = 1 / (cTime - pTime)
        pTime = cTime


        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)
        '''
        1. img = where to put text
        2. str(int(fps)) = the message that want to put
        3. (10, 70) = location of text in the frame
        4. cv2.FONT_HERSHEY_PLAIN = font type
        5. 3 = font size
        6. (255, 0,255) = font color
        7. 3 = font thickness
        '''

        cv2.imshow("Video Window", img)
        cv2.waitKey(1)

if __name__ == "__main__":
    main()
